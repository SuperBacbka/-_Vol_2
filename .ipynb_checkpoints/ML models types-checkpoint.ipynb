{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c895123-194a-4a4c-9ee4-371a6319c280",
   "metadata": {},
   "source": [
    "# Виды моделей машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c0699-fc62-46d2-aa54-ffc0ca699887",
   "metadata": {},
   "source": [
    "<img src='https://i.vas3k.blog/7ry.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e6153-a25d-4a92-840f-f2cab2abb1ce",
   "metadata": {},
   "source": [
    "За некоторое время мы с вами успели поговорить про машинное обучение, его задачи, библиотеки для использования различных методов анализа и преобразования данных.  \n",
    "В этот раз настал момент поговорить про __виды моделей машинного обучения__ и различных связанных с задачами ML алгоритмами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38866dba-e68c-4c2e-a3c9-c18079a83cae",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb9c7cf-830e-49b4-b8ba-ac11f1c18531",
   "metadata": {},
   "source": [
    "Затронем мы сегодня Классическое обучение так называемый Classic ML и Ансамблевые методы которые тоже могут в него включаться и выполняют примерно те же задачи но немного по другому, более сложному пути, что может наградить искателя лучшей моделью в итоге"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff43b3a-7a89-4c53-a181-ddb3ca4fd887",
   "metadata": {},
   "source": [
    "Но перед началом раз у нас есть возможность и такая красивая картинка __обсудим карту машинного обучения__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca4dfa-0738-4ec3-b951-d7729c3f4928",
   "metadata": {},
   "source": [
    "# Обучение с подкреплением"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd84498a-ae1e-42fe-9437-611d97be91f4",
   "metadata": {},
   "source": [
    "Это сфера машинного обучения когда нейросеть сама учится выполнять задачу. Причем изначально эта задача никак не ставится. Алгоритм может только выполнять какие-то действия и получать за эти действия награду (или штраф). Это подобно естественному обучению человека (или любого другого животного) без учителя, когда субъект выполняет какие-то действия и запоминает, приносят ли эти действия комфорт или дискомфорт. Например, однажды прикоснувшись к горячему чайнику, вы запомнили, что это действие приносит дискомфорт (или \"штраф\"), и более стараетесь избегать прикосновений к горячим предметам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8774cc-03bd-4d1e-a688-ba4050af691f",
   "metadata": {},
   "source": [
    "https://habr.com/ru/articles/789218/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc15f5-bad3-45e4-b4c0-89e04fdf6159",
   "metadata": {},
   "source": [
    "# Нейросети и глубокое обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424d596-6877-4f84-8ebb-e73b5167bdcb",
   "metadata": {},
   "source": [
    "Сфера нейросетей в машинном обучении в первозданном виде довольна похожа на классический ML, с помощью нейросетей можно делать и классификацию и регрессию и с этим различных проблем не должно возникнуть. Но главная особенность нейросетей как по крайней мере я считаю - это то, что архитектура нейросетей позволяет настраивать её внутренние слои, корректировать под себя входной, выходной слой и другие преобразования внутри."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93023ba5-7556-449e-b1c7-7b6f0c2296ae",
   "metadata": {},
   "source": [
    "Из-за такой настраиваемости и гибкости под задачу, большого потенциала таких углубленных алгоритмов - нейросети используются во всеразличных сферах и задачах"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d4242-db3c-4f0f-b09b-b1b42a8135c6",
   "metadata": {},
   "source": [
    "# Classic ML и Ансамблевые методы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a781654f-14d6-4503-a10b-b8403f435f8f",
   "metadata": {},
   "source": [
    "# Без учителя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c397cc-e62f-4044-9f65-9e9506b7e8f2",
   "metadata": {},
   "source": [
    "## Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f16a6-6b91-4630-916e-b50221744f85",
   "metadata": {},
   "source": [
    "Задача кластеризации подразумевает __набор данных без какой либо явно обозначенной целевой переменной__, и на основе этих данных говоря простыми словами мы хотим сгруппировать и рассклассифицировать наши данные по каким-то доселе не представленным в наборе данных классам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3548754-3f99-45e9-96ec-2b2ae824b864",
   "metadata": {},
   "source": [
    "Основные цели кластеризации:\n",
    "\n",
    "- Понимание. \n",
    "\n",
    "Деление разрозненных данных на группы помогает аналитику понять, какие именно данные собраны. Потом их проще будет обрабатывать — например, применять к разным кластерам конкретные методы анализа.\n",
    "- Выявление аномалий. \n",
    "\n",
    "После кластеризации могут появиться отдельные данные, которые не относятся ни к одному из кластеров. Их нужно изучить, чтобы понять, ошибка это или какой-то интересный феномен.\n",
    "- Расширение. \n",
    "\n",
    "Иногда при сборе информации у каких-то данных больше признаков, а у каких-то меньше. Кластеризация поможет предположить отсутствующие признаки у других элементов кластера.\n",
    "- Сжатие. \n",
    "\n",
    "Если данных слишком много, можно поделить их на кластеры, усреднить и оставить по одному объекту на каждый кластер. Это позволит в дальнейшем при анализе использовать меньше мощности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c948982-5b31-4c17-be65-1c589dc6b3a0",
   "metadata": {},
   "source": [
    "## Уменьшение размерности, обобщение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736cf288-80d9-4ca4-aa79-6f6a5faa4be4",
   "metadata": {},
   "source": [
    "Задача уменьшения размерности в основном подразумевает уменьшение числа признаков набора данных. И решает некоторые задачи которые могут возникнуть в ходе анализа данных:\n",
    "- Сокращение количества признаков\n",
    "\n",
    "Наличие признаков избыточных, неинформативных или слабо информативных может понизить эффективность модели, а после сокращения числа таких колонок модель упрощается, и соответственно уменьшается размер набора данных в памяти, ускоряется работа алгоритмов ML на нем или например может улучшиться качество предсказания модели из-за зашумления данных близкими по значению колонками  \n",
    "- Задача визуализации данных\n",
    "\n",
    "Все мы хотим не только видеть циферки а взглянуть на данные со стороны визуализации в чём уменьшение размерности может нам помочь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be8400-a395-4b30-80d0-ef158636d2b0",
   "metadata": {},
   "source": [
    "## Поиск ассоциативных правил (Associations rules learning — ARL))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce797523-bc25-4ee4-93fc-79e10c902633",
   "metadata": {},
   "source": [
    "В общем виде ARL можно описать как «Кто купил x, также купил y». В основе лежит анализ транзакций, внутри каждой из которых лежит свой уникальный itemset из набора items где:  \n",
    "> itemset - наш условный dataframe в котором  \n",
    "> items - колонки нашего датафрейма преимущественно в виде бинарных данных (купил - 1/ не купил - 0).  \n",
    ">\n",
    "При помощи ARL алогритмов находятся те самые «правила» совпадения items внутри одной транзакции, которые потом сортируются по их силе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe4dbd-5ce0-42bc-b191-67ba7f3a7dc9",
   "metadata": {},
   "source": [
    "https://habr.com/ru/companies/ods/articles/353502/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4d266f-a343-4b6a-be46-06761334f5ab",
   "metadata": {},
   "source": [
    "# С учителем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3fded-2410-4721-80d5-e8783dab2ecb",
   "metadata": {},
   "source": [
    "## Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10300b93-64cd-4559-8763-4dd7c0302a78",
   "metadata": {},
   "source": [
    "Задача классификации подразумевает что модель по каким-то признакам в наших данных разделить каждую строку в датафрейме на какой-то определённый класс, а так как обучение с учителем - эта классификация известна и предоставлена в данных и по ней мы говорим модели распределить строки у которых класс не известен  \n",
    "\n",
    "«Разделяет объекты по заранее известному признаку. Носки по цветам, документы по языкам, музыку по жанрам»\n",
    "\n",
    "Сегодня используют для:\n",
    "\n",
    "- Спам-фильтры\n",
    "- Определение языка\n",
    "- Поиск похожих документов\n",
    "- Анализ тональности\n",
    "- Распознавание рукописных букв и цифр\n",
    "- Определение подозрительных транзакций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0e205-bb57-4607-b487-202d0e42314b",
   "metadata": {},
   "source": [
    "## Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6035148-5fb1-4ffe-9e6f-edc521936057",
   "metadata": {},
   "source": [
    "Задача же регрессии с которой вы сталкивались подразумевает что модель должна по признакам в данных определить какое-то определённое числовое значение  \n",
    "\n",
    "Сегодня используют для:\n",
    "\n",
    "- Прогноз стоимости ценных бумаг\n",
    "- Анализ спроса, объема продаж\n",
    "- Любые зависимости числа от времени"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fe041f-eb84-49f6-aea5-00d51da74edc",
   "metadata": {},
   "source": [
    "## Ансамблевые методы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce5c9fd-499e-4d02-a12d-0b066d72327f",
   "metadata": {},
   "source": [
    "В основе ансамблевых методов стоят не определённые задачи которые они решают а различные способы объединения разных моделей в одну с целью улучшения предсказаний. Таким образом различают:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb47a7-2bdb-4b7e-afdd-34bb203ca774",
   "metadata": {},
   "source": [
    "### Стекинг\n",
    "Работа этого типа ансамблей довольно проста. На вход всех слабых прогнозаторов подаётся обучающий набор, каждый прогноз идёт к финальной модели, которая называется смеситель, мета-ученик или мета-модель, после чего та вырабатывает финальный прогноз."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5183ae6-353d-47d5-bd3d-75d526edf93a",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/r/w1560/getpro/habr/upload_files/139/8cd/1c9/1398cd1c90c6e69f7e50e3b1fc783c35.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22321298-4492-4ff8-936c-76bde9ebe38b",
   "metadata": {},
   "source": [
    "### Бэггинг\n",
    "Основная идея бэггинга заключается в том, чтобы обучить несколько одинаковых моделей на разных образцах. Распределение выборки неизвестно, поэтому модели получатся разными.\n",
    "\n",
    "Для начала генерируется несколько бутстрэп-выборок. Бутстрэп - это случайный выбор данных из датасета и представление их в модель, затем данные возвращаются в датасет и процесс повторяется. После модели делают свои прогнозы на основе бутстрэп-выборок. В случае регрессии прогнозы просто усредняются. В случае же классификации применяется голосование."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f061d4-7fa3-4338-8e77-f0fc08972dc5",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/r/w1560/getpro/habr/upload_files/e69/3c2/2c7/e693c22c75565b0a4a0bc38220ab5a6b.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d6d3a-dd50-4be6-bb7b-b08383c9aaa4",
   "metadata": {},
   "source": [
    "### Бустинг\n",
    "Метод бустинга в чём то схож с методом бэггинга: берётся множество одинаковых моделей и объединяется, чтобы получить сильного ученика. Но разница заключается в том, что модели приспосабливаются к данным последовательно, то есть каждая модель будет исправлять ошибки предыдущей.\n",
    "\n",
    "Базовые модели для бустинга - это модели с низким разбросом и высоким смещением. Например неглубокие деревья решений. Одна из причин такого выбора моделей - они требуют меньше вычислительных затрат. Ещё бустинг (в отличии от бэггинга) нельзя распараллелить."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479ef80-98ca-45f8-a5d3-0c6dbf8a21db",
   "metadata": {},
   "source": [
    "<img src='https://heung-bae-lee.github.io/image/bagging_boosting_difference.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc6a325-6485-408f-abc3-f4565ace1e89",
   "metadata": {},
   "source": [
    "<img src='https://almablog-media.s3.ap-south-1.amazonaws.com/image5_db7dce9736.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae375031-ec20-46aa-b299-e640a79a51ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://habr.com/ru/articles/571296/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e192f3c-5ffc-4073-ba5a-5f870b233c55",
   "metadata": {},
   "source": [
    "# Типы моделей ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d922a6d-b1c2-4802-8b48-191056da9a1b",
   "metadata": {},
   "source": [
    "Сейчас попробуем разобрать разные семейства моделей которые можно встретить на своём пути в изучении ML.\n",
    "\n",
    "В основном эти семейста строго не делятся на только регрессию и только классификацию, так как практически всегда есть способ транслировать регрессию в классификацию, а функцию классификации преобразовать так, чтобы она решала задачу регрессии\n",
    "\n",
    "Поэтому поговорим именно о семействах моделей и чем они отличаются"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dc5bb0-d043-4b5f-8042-00948a93dc34",
   "metadata": {},
   "source": [
    "## Линейные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a881be-7523-45f2-a4c3-4255d7d4ef4a",
   "metadata": {},
   "source": [
    "Обобщающий фактор всех линейных моделей — это линейная зависимость между переменными. Все эти модели предполагают, что зависимость между объясняемой (зависимой) переменной и одной или несколькими независимыми переменными можно описать с помощью линейной функции. В этом контексте \"линейность\" означает, что изменения в независимых переменных приводят к пропорциональным изменениям в зависимой переменной, независимо от их значения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd765b4-7a2a-456d-93dc-0ea4f34744eb",
   "metadata": {},
   "source": [
    "<img src='https://yastatic.net/s3/education-portal/media/1_1_02255c591c_b62e3f69e1.webp'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29afd2b7-c50d-4851-817c-300df0690097",
   "metadata": {},
   "source": [
    "Основной принцип всех линейных моделей — это поиск линейных зависимостей между переменными, с минимизацией ошибки предсказания, чтобы лучше понимать и прогнозировать поведение зависимой переменной на основе независимых факторов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3110271-cdff-4421-9fcb-15d11f13c7c8",
   "metadata": {},
   "source": [
    "### Представители:\n",
    "- Линейная регрессия\n",
    "- Логистическая регрессия\n",
    "- Линейный дискриминантный анализ (LDA)\n",
    "- Ридж-регрессия (Ridge regression)\n",
    "- Лассо-регрессия (Lasso regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ebd8d-c2b8-437c-8dd0-148022329e31",
   "metadata": {},
   "source": [
    "## Методы на основе байесовского подхода"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a43bc2-6f68-4cdb-91ec-83be3221ab9e",
   "metadata": {},
   "source": [
    "Эти модели основываются на теореме Байеса, которая позволяет обновлять вероятность гипотезы на основе новых данных. Модели Байеса часто используются для задач классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1fe4a7-e383-4b6b-a573-7e0f71cd2b57",
   "metadata": {},
   "source": [
    "<img src='https://sun9-36.userapi.com/impf/c830708/v830708267/1695f2/NMpexjpc9QU.jpg?size=900x434&quality=96&sign=61e51059c04f42926ca1ffa1b7a963c0&c_uniq_tag=t2orJGo5WKqqrzTYVwd3pyXTfEWR2ebXl0b0K8iNbEU&type=album'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a31ec-66d5-4d8f-ad4d-1889be330504",
   "metadata": {},
   "source": [
    "https://habr.com/ru/companies/otus/articles/473468/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a014b46b-d93f-49b4-8be1-cf71fea27759",
   "metadata": {},
   "source": [
    "### Представители:\n",
    "- Наивный байесовский классификатор (Naive Bayes)\n",
    "- Байесовская сеть (Bayesian Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e2b64-de62-4179-8dbd-c91ead5ed227",
   "metadata": {},
   "source": [
    "https://habr.com/ru/companies/otus/articles/733598/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df42803-e8af-43cb-8d50-2778c063db49",
   "metadata": {},
   "source": [
    "## Методы опорных векторов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02efd317-6dc4-4383-9a58-e882747ba063",
   "metadata": {},
   "source": [
    "это техника машинного обучения с учителем. Она используется в классификации, может быть применена к регрессионным задачам.\n",
    "\n",
    "Метод определяет границу принятия решения вместе с максимальным зазором, который разделяет почти все точки на два класса, оставляя место для неправильной классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0681da3d-c3b2-40b7-884d-530d64d8f3a9",
   "metadata": {},
   "source": [
    "Простыми словами он ищет, как так провести две прямые между категориями, чтобы между ними образовался наибольший зазор. На картинке видно нагляднее:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f4195-8e77-4f38-9bda-1af577843ecd",
   "metadata": {},
   "source": [
    "<img src='https://i.vas3k.blog/7rh.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f841b-0bef-41d9-bf5c-434e791107c5",
   "metadata": {},
   "source": [
    "Представители:\n",
    "- Метод опорных векторов (SVM):\n",
    "- Ядерный метод регрессии (SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79529962-3df0-4f68-a3c2-292810a323f3",
   "metadata": {},
   "source": [
    "## Методы на основе соседей\n",
    "\n",
    "К-ближайших соседей (K-Nearest Neighbors или просто KNN) — алгоритм классификации и регрессии, основанный на гипотезе компактности, которая предполагает, что расположенные близко друг к другу объекты в пространстве признаков имеют схожие значения целевой переменной или принадлежат к одному классу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c380e1d-3b0c-4188-b5db-6b8bc240ff1b",
   "metadata": {},
   "source": [
    "<img src='https://habrastorage.org/r/w1560/getpro/habr/upload_files/d52/7ad/f37/d527adf3736a6981fa510e2bfca24b7f.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6b672-b16a-476b-b254-5bd60f71d12b",
   "metadata": {},
   "source": [
    "Представители:\n",
    "- Метод k ближайших соседей (k-NN)\n",
    "- K-средних (K-means) для кластеризации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d6099-c7ac-4c3f-8a42-fe73788ea84c",
   "metadata": {},
   "source": [
    "# Деревья решений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be763f08-99cc-45d1-a7fc-2974323d35fc",
   "metadata": {},
   "source": [
    "Деревья решений используются в повседневной жизни в самых разных областях человеческой деятельности, порой и очень далеких от машинного обучения. Деревом решений можно назвать наглядную инструкцию, что делать в какой ситуации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e750a7a-04ef-4a7f-9c48-c502a15bab22",
   "metadata": {},
   "source": [
    "И в Машинном обучения такие деревья строятся на основе понятии о энтропие (Энтропия Шеннона), которое соответствует степени хаоса в системе. Чем выше энтропия, тем менее упорядочена система и наоборот. Это поможет нам формализовать \"эффективное разделение выборки\" для наших деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d547fac-91b2-4d1e-9ca1-e49e4754d07c",
   "metadata": {},
   "source": [
    "<img src='https://i.vas3k.blog/7rd.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0365992-822e-487c-812f-d9736f6ecaa5",
   "metadata": {},
   "source": [
    "В чистом виде деревья сегодня используют редко, но вот их ансамбли (о которых будет ниже) лежат в основе крупных систем и зачастую уделывают даже нейросети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a1b08-f336-4c0a-9b6b-317102e9d1de",
   "metadata": {},
   "source": [
    "Представители:\n",
    "- Дерево решений (Decision Tree)\n",
    "- Метод случайного леса (Random Forest)\n",
    "- Градиентный бустинг (Gradient Boosting Machines, например, XGBoost, LightGBM, CatBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f8f0f4-849c-4543-b85b-09b08f19d1cb",
   "metadata": {},
   "source": [
    "https://habr.com/ru/companies/ods/articles/322534/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cca5e0-a46f-4de0-9346-1dee80432b5b",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed058836-daab-49ee-b652-a79f6fc1fcf0",
   "metadata": {},
   "source": [
    "Материал был взян со следующей статьи:  \n",
    "https://vas3k.blog/blog/machine_learning/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
